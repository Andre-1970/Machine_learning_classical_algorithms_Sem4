{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Andre-1970/Machine_learning_classical_algorithms_Sem4/blob/main/3_11_%D0%94%D0%BE%D0%BC%D0%B0%D1%88%D0%BD%D1%8F%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cisB24TazhU2"
   },
   "source": [
    "### Домашняя работа\n",
    "\n",
    "**Задание простого уровня** Мы говорили, что метрики качества нужны, чтобы сравнивать различные модели между собой. В задаче полиномиальной регрессии реализуйте код для выбора лучшей степени полиному:\n",
    "\n",
    "* возьмите все степени от 1 до 10 по порядку, без пропусков.\n",
    "* найдите степень полинома, где будет лучший r2-score\n",
    "* напишите код, который выводит самую подходящую степень полинома и соответствующий ей скор\n",
    "\n",
    "Эта процедура называется Grid Search и помогает найти лучшие параметры для модели.\n",
    "\n",
    "Обучите лучшую модель и сделайте predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "degrees = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "best_score = 0.0\n",
    "best_degree = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/phones.csv')\n",
    "# разделение признаков и целевой переменной\n",
    "X = df[['disk', 'year']]\n",
    "y = df['price']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Переберем все степени и найдем лучший R2-score\n",
    "for degree in degrees:\n",
    "    # Создадим полиномиальные признаки\n",
    "    poly_features = PolynomialFeatures(degree)\n",
    "    X_poly = poly_features.fit_transform(X)\n",
    "    # Обучим модель\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_poly, y)\n",
    "\n",
    "    # Вычислим R2-score\n",
    "    score = r2_score(y, model.predict(X_poly))\n",
    "\n",
    "    # Если R2-score лучше, чем текущий лучший, обновим переменные\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_degree = degree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best degree: 9\n",
      "Best R2-score: 0.9943138168888681\n",
      "Predictions: [ 7562.57611915  7345.33051655  1677.40295002 14835.58109257\n",
      "  4043.55809948 15810.70185539  7345.33051655  4658.04765007\n",
      " 12707.54276535  6582.52661106 13790.47771332 10759.59111091\n",
      "  9557.69453308  5214.90372536  7008.15501282  2250.62603542\n",
      " 12707.54276535  5998.16981384 13158.91097996 12090.86844704\n",
      "  1383.44454643  4658.04765007 10558.26303837  9620.38674137\n",
      "  8571.01982281  6582.52661106  8441.97591278  9038.25140259\n",
      "  2380.7844331  12707.54276535 11619.22429058  4870.86700889\n",
      "  7008.15501282  4994.32917377  7562.57611915  5958.78547356\n",
      " 12707.54276535 15810.70185539  7562.57611915  4658.04765007\n",
      " 14835.58109257 12707.54276535  5257.93419525  8441.97591278\n",
      "  7562.57611915  7345.33051655  9620.38674137  2699.55728886\n",
      " 10558.26303837 13158.91097996 10042.74772903  8030.69995758\n",
      "  3133.17899963  1677.40295002  8030.69995758  7871.35931179\n",
      "  1431.85556766 12707.54276535 10558.26303837 12090.86844704\n",
      " 10558.26303837  4658.04765007  5214.90372536  8216.33215782\n",
      "  3087.32851192  9620.38674137  7345.33051655  4870.86700889\n",
      "  4658.04765007 12090.86844704 11056.23521397 10558.26303837\n",
      "  8216.33215782  8650.85212776 12090.86844704  4043.55809948\n",
      "  5998.16981384  8650.85212776  6268.4037759   9557.69453308\n",
      "  2699.55728886  2380.7844331   4281.48946735 10042.74772903\n",
      "  7325.50983116  4658.04765007 10042.74772903  9038.25140259\n",
      " 14835.58109257  8650.85212776 13158.91097996  8650.85212776\n",
      "  7067.86989567  7067.86989567  8441.94510815  8650.85212776\n",
      "  7562.57611915  5257.93419525  7325.50983116  9038.25140259]\n"
     ]
    }
   ],
   "source": [
    "# Выведем лучшую степень и соответствующий ей R2-score\n",
    "print(\"Best degree:\", best_degree)\n",
    "print(\"Best R2-score:\", best_score)\n",
    "\n",
    "# Обучим лучшую модель и построим предсказания\n",
    "poly_features = PolynomialFeatures(best_degree)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)\n",
    "y_pred = model.predict(X_poly)\n",
    "\n",
    "# Выведем предсказания\n",
    "print(\"Predictions:\", y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3dSmlAFzhU9"
   },
   "source": [
    "**Задание среднего уровня** Напишите класс для обучения модели, который содержит:\n",
    "\n",
    "* функцию `.fit(X, y)` , которая принимает на вход массив фичей `X`, массив таргетов `y` и обучает коэффициенты регрессии. Код для обучения взять из первого урока модуля *Постановка ML задачи линейной регрессии*\n",
    "* функцию `.predict(X)`, которая по массиву фичей `X` возвращает массив предсказаний `y`\n",
    "\n",
    "Нужно использовать код для аналитически вычисляемых коэффициентов. \n",
    "\n",
    "Это задание позволит понять, как работает линейная регрессия \"внутри\" библиотечной реализации."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rayvZFx1zhU9"
   },
   "source": [
    "class CustomLinearReg:\n",
    "    def __init__(self):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "        self.intercept_ = self.coef_[0]\n",
    "        self.coef_ = self.coef_[1:]\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        return X @ np.hstack((self.intercept_, self.coef_))"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 370.5450395136257\n",
      "MSE: 207228.6017281483\n",
      "RMSE: 455.2236831802013\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/phones.csv')\n",
    "# разделение признаков и целевой переменной\n",
    "X = df[['disk', 'year']]\n",
    "y = df['price']\n",
    "\n",
    "# разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = CustomLinearReg()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'MSE: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwWP7aPOzhVA"
   },
   "source": [
    "**Задание высокого уровня**\n",
    "\n",
    "1. разделите датасет с домами Бостона из Урока 2 (таргет и фичи) на две части: в одной части 80% датасета (назовём train) в другой 20% (назовём valid) с помощью функции `train_test_split` из библиотеки `sklearn`\n",
    "1. обучите модель только на train датасете\n",
    "1. постройте предсказания valid датасете\n",
    "1. Посчитайте  `r2 score` на валидационном сете\n",
    "\n",
    "После этого примените к обеим датасетам z-преобразование и повторите шаги 2-4. Как изменилась метрика r2?\n",
    "\n",
    "Это задание поможет понять, как валидировать линейную регрессию (и другие модели) на отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data/phones.csv')\n",
    "# разделение признаков и целевой переменной\n",
    "X = df[['disk', 'year']]\n",
    "y = df['price']\n",
    "\n",
    "# делим датасет на train и valid\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 до преобразования: 0.9788\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#2\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "#3\n",
    "score_before = r2_score(y_valid, y_pred)\n",
    "\n",
    "#4\n",
    "print(f\"R2 до преобразования: {score_before:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 после преобразования: 0.9788\n"
     ]
    }
   ],
   "source": [
    "X_train_z = X_train.apply(zscore)\n",
    "X_valid_z = X_valid.apply(zscore)\n",
    "\n",
    "#1\n",
    "model.fit(X_train_z, y_train)\n",
    "\n",
    "#2\n",
    "y_pred_valid_z = model.predict(X_valid_z)\n",
    "\n",
    "#3\n",
    "score_after = r2_score(y_valid, y_pred_valid_z)\n",
    "\n",
    "#4\n",
    "print(f\"R2 после преобразования: {score_before:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изменение метрики R2: 0.0009132858981966141\n"
     ]
    }
   ],
   "source": [
    "print(f'Изменение метрики R2: {score_before-score_after}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
