{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Andre-1970/Machine_learning_classical_algorithms_Sem4/blob/main/3_11_%D0%94%D0%BE%D0%BC%D0%B0%D1%88%D0%BD%D1%8F%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cisB24TazhU2"
   },
   "source": [
    "### Домашняя работа\n",
    "\n",
    "**Задание простого уровня** Мы говорили, что метрики качества нужны, чтобы сравнивать различные модели между собой. В задаче полиномиальной регрессии реализуйте код для выбора лучшей степени полиному:\n",
    "\n",
    "* возьмите все степени от 1 до 10 по порядку, без пропусков.\n",
    "* найдите степень полинома, где будет лучший r2-score\n",
    "* напишите код, который выводит самую подходящую степень полинома и соответствующий ей скор\n",
    "\n",
    "Эта процедура называется Grid Search и помогает найти лучшие параметры для модели.\n",
    "\n",
    "Обучите лучшую модель и сделайте predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import zscore\n",
    "from sklearn.datasets import fetch_openml"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "degrees = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "best_score = 0.0\n",
    "best_degree = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/phones.csv')\n",
    "# разделение признаков и целевой переменной\n",
    "X = df[['disk', 'year']]\n",
    "y = df['price']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Переберем все степени и найдем лучший R2-score\n",
    "for degree in degrees:\n",
    "    # Создадим полиномиальные признаки\n",
    "    poly_features = PolynomialFeatures(degree)\n",
    "    X_poly = poly_features.fit_transform(X)\n",
    "    # Обучим модель\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_poly, y)\n",
    "\n",
    "    # Вычислим R2-score\n",
    "    score = r2_score(y, model.predict(X_poly))\n",
    "\n",
    "    # Если R2-score лучше, чем текущий лучший, обновим переменные\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_degree = degree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best degree: 9\n",
      "Best R2-score: 0.9943138168888681\n",
      "Predictions: [ 7562.57611915  7345.33051655  1677.40295002 14835.58109257\n",
      "  4043.55809948 15810.70185539  7345.33051655  4658.04765007\n",
      " 12707.54276535  6582.52661106 13790.47771332 10759.59111091\n",
      "  9557.69453308  5214.90372536  7008.15501282  2250.62603542\n",
      " 12707.54276535  5998.16981384 13158.91097996 12090.86844704\n",
      "  1383.44454643  4658.04765007 10558.26303837  9620.38674137\n",
      "  8571.01982281  6582.52661106  8441.97591278  9038.25140259\n",
      "  2380.7844331  12707.54276535 11619.22429058  4870.86700889\n",
      "  7008.15501282  4994.32917377  7562.57611915  5958.78547356\n",
      " 12707.54276535 15810.70185539  7562.57611915  4658.04765007\n",
      " 14835.58109257 12707.54276535  5257.93419525  8441.97591278\n",
      "  7562.57611915  7345.33051655  9620.38674137  2699.55728886\n",
      " 10558.26303837 13158.91097996 10042.74772903  8030.69995758\n",
      "  3133.17899963  1677.40295002  8030.69995758  7871.35931179\n",
      "  1431.85556766 12707.54276535 10558.26303837 12090.86844704\n",
      " 10558.26303837  4658.04765007  5214.90372536  8216.33215782\n",
      "  3087.32851192  9620.38674137  7345.33051655  4870.86700889\n",
      "  4658.04765007 12090.86844704 11056.23521397 10558.26303837\n",
      "  8216.33215782  8650.85212776 12090.86844704  4043.55809948\n",
      "  5998.16981384  8650.85212776  6268.4037759   9557.69453308\n",
      "  2699.55728886  2380.7844331   4281.48946735 10042.74772903\n",
      "  7325.50983116  4658.04765007 10042.74772903  9038.25140259\n",
      " 14835.58109257  8650.85212776 13158.91097996  8650.85212776\n",
      "  7067.86989567  7067.86989567  8441.94510815  8650.85212776\n",
      "  7562.57611915  5257.93419525  7325.50983116  9038.25140259]\n"
     ]
    }
   ],
   "source": [
    "# Выведем лучшую степень и соответствующий ей R2-score\n",
    "print(\"Best degree:\", best_degree)\n",
    "print(\"Best R2-score:\", best_score)\n",
    "\n",
    "# Обучим лучшую модель и построим предсказания\n",
    "poly_features = PolynomialFeatures(best_degree)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)\n",
    "y_pred = model.predict(X_poly)\n",
    "\n",
    "# Выведем предсказания\n",
    "print(\"Predictions:\", y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3dSmlAFzhU9"
   },
   "source": [
    "**Задание среднего уровня** Напишите класс для обучения модели, который содержит:\n",
    "\n",
    "* функцию `.fit(X, y)` , которая принимает на вход массив фичей `X`, массив таргетов `y` и обучает коэффициенты регрессии. Код для обучения взять из первого урока модуля *Постановка ML задачи линейной регрессии*\n",
    "* функцию `.predict(X)`, которая по массиву фичей `X` возвращает массив предсказаний `y`\n",
    "\n",
    "Нужно использовать код для аналитически вычисляемых коэффициентов. \n",
    "\n",
    "Это задание позволит понять, как работает линейная регрессия \"внутри\" библиотечной реализации."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rayvZFx1zhU9"
   },
   "source": [
    "class CustomLinearReg:\n",
    "    def __init__(self):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        self.coef_ = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "        self.intercept_ = self.coef_[0]\n",
    "        self.coef_ = self.coef_[1:]\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "        return X @ np.hstack((self.intercept_, self.coef_))"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 370.5450395136257\n",
      "MSE: 207228.6017281483\n",
      "RMSE: 455.2236831802013\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/phones.csv')\n",
    "# разделение признаков и целевой переменной\n",
    "X = df[['disk', 'year']]\n",
    "y = df['price']\n",
    "\n",
    "# разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = CustomLinearReg()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'MSE: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwWP7aPOzhVA"
   },
   "source": [
    "**Задание высокого уровня**\n",
    "\n",
    "1. разделите датасет с домами Бостона из Урока 2 (таргет и фичи) на две части: в одной части 80% датасета (назовём train) в другой 20% (назовём valid) с помощью функции `train_test_split` из библиотеки `sklearn`\n",
    "1. обучите модель только на train датасете\n",
    "1. постройте предсказания valid датасете\n",
    "1. Посчитайте  `r2 score` на валидационном сете\n",
    "\n",
    "После этого примените к обеим датасетам z-преобразование и повторите шаги 2-4. Как изменилась метрика r2?\n",
    "\n",
    "Это задание поможет понять, как валидировать линейную регрессию (и другие модели) на отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS CHAS    NOX     RM   AGE     DIS RAD    TAX  PTRATIO  \\\n",
      "0  0.00632  18.0   2.31    0  0.538  6.575  65.2  4.0900   1  296.0     15.3   \n",
      "1  0.02731   0.0   7.07    0  0.469  6.421  78.9  4.9671   2  242.0     17.8   \n",
      "2  0.02729   0.0   7.07    0  0.469  7.185  61.1  4.9671   2  242.0     17.8   \n",
      "3  0.03237   0.0   2.18    0  0.458  6.998  45.8  6.0622   3  222.0     18.7   \n",
      "4  0.06905   0.0   2.18    0  0.458  7.147  54.2  6.0622   3  222.0     18.7   \n",
      "\n",
      "        B  LSTAT  \n",
      "0  396.90   4.98  \n",
      "1  396.90   9.14  \n",
      "2  392.83   4.03  \n",
      "3  394.63   2.94  \n",
      "4  396.90   5.33  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\___project\\python\\Machine_learning_classical_algorithms_Sem4\\venv\\lib\\site-packages\\sklearn\\datasets\\_openml.py:292: UserWarning: Multiple active versions of the dataset matching the name boston exist. Versions may be fundamentally different, returning version 1.\n",
      "  warn(\n",
      "C:\\___project\\python\\Machine_learning_classical_algorithms_Sem4\\venv\\lib\\site-packages\\sklearn\\datasets\\_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "boston_dataset = fetch_openml(name='boston')\n",
    "boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "print(boston.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  target   506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "non_numeric_columns = boston.select_dtypes(include=['category']).columns.tolist()\n",
    "for name in non_numeric_columns:\n",
    "    boston[name] = boston[name].astype('float64')\n",
    "\n",
    "boston.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.99672362 36.02556534 14.81694405 25.03197915 18.76987992 23.25442929\n",
      " 17.66253818 14.34119    23.01320703 20.63245597 24.90850512 18.63883645\n",
      " -6.08842184 21.75834668 19.23922576 26.19319733 20.64773313  5.79472718\n",
      " 40.50033966 17.61289074 27.24909479 30.06625441 11.34179277 24.16077616\n",
      " 17.86058499 15.83609765 22.78148106 14.57704449 22.43626052 19.19631835\n",
      " 22.43383455 25.21979081 25.93909562 17.70162434 16.76911711 16.95125411\n",
      " 31.23340153 20.13246729 23.76579011 24.6322925  13.94204955 32.25576301\n",
      " 42.67251161 17.32745046 27.27618614 16.99310991 14.07009109 25.90341861\n",
      " 20.29485982 29.95339638 21.28860173 34.34451856 16.04739105 26.22562412\n",
      " 39.53939798 22.57950697 18.84531367 32.72531661 25.0673037  12.88628956\n",
      " 22.68221908 30.48287757 31.52626806 15.90148607 20.22094826 16.71089812\n",
      " 20.52384893 25.96356264 30.61607978 11.59783023 20.51232627 27.48111878\n",
      " 11.01962332 15.68096344 23.79316251  6.19929359 21.6039073  41.41377225\n",
      " 18.76548695  8.87931901 20.83076916 13.25620627 20.73963699  9.36482222\n",
      " 23.22444271 31.9155003  19.10228271 25.51579303 29.04256769 20.14358566\n",
      " 25.5859787   5.70159447 20.09474756 14.95069156 12.50395648 20.72635294\n",
      " 24.73957161 -0.164237   13.68486682 16.18359697 22.27621999 24.47902364]\n",
      "R2 score: 0.6687594935356289\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "X = boston.drop('target', axis=1)\n",
    "y = boston.target\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#2\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#3\n",
    "y_pred = model.predict(X_valid)\n",
    "print(y_pred)\n",
    "\n",
    "#4\n",
    "r2 = r2_score(y_valid, y_pred)\n",
    "print(f'R2 score: {r2}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.32141926 38.34541052 16.58140478 26.57522306 19.93035763 25.16444263\n",
      " 19.385686   15.78559222 24.33265774 22.27734901 27.39702904 20.85314996\n",
      " -6.10221485 23.5725713  20.55562866 27.6411157  22.29649     6.53674576\n",
      " 43.44143521 18.66845004 28.92183863 32.07132489 12.44729253 25.56675924\n",
      " 18.90412441 16.8529762  24.49761815 15.72936632 24.45628755 20.73101348\n",
      " 24.55864222 26.72707585 27.21648499 18.48151062 18.05719421 19.13606178\n",
      " 33.35435437 21.22882794 25.75442313 26.24521667 15.42797704 34.18994554\n",
      " 45.61371152 18.77748368 29.35733019 17.99300145 15.17010984 27.5642953\n",
      " 21.55636132 32.44683349 23.50187845 36.95046121 17.27141279 27.74147087\n",
      " 42.73910533 23.75115832 19.9587603  34.3745656  26.87261094 14.12238181\n",
      " 23.96748336 32.20281507 33.55284288 16.85049    21.64481952 18.59440578\n",
      " 21.74500974 27.56057587 32.3639105  12.61941854 22.26773345 28.85183546\n",
      " 11.92572786 16.03364553 25.63780968  6.62238647 23.01682534 44.30872591\n",
      " 19.94330116 10.5279837  22.32848502 14.48442071 22.51830218 10.15378444\n",
      " 25.0229207  34.27233979 20.34736764 26.98776614 30.87588589 21.56298023\n",
      " 27.71408851  6.27865529 21.39878242 16.36670696 12.79922516 22.04035668\n",
      " 25.93501571  0.5484158  14.65059011 17.49657808 24.02779599 26.31913356]\n",
      "R2 score: 0.6276100798863373\n",
      "Изменение R2 после применения z-преобразования: -0.04114941364929159\n"
     ]
    }
   ],
   "source": [
    "#применение z-преобразования\n",
    "z_X_train = (X_train - X_train.mean()) / X_train.std()\n",
    "z_X_valid = (X_valid - X_valid.mean()) / X_valid.std()\n",
    "\n",
    "#2\n",
    "model = LinearRegression()\n",
    "model.fit(z_X_train, y_train)\n",
    "\n",
    "#3\n",
    "z_y_pred = model.predict(z_X_valid)\n",
    "print(z_y_pred)\n",
    "\n",
    "#4\n",
    "z_r2 = r2_score(y_valid, z_y_pred)\n",
    "print(f'R2 score: {z_r2}')\n",
    "\n",
    "print(f'Изменение R2 после применения z-преобразования: {z_r2 - r2}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
